



@article{sensor,
  title={Computer vision-based robotic arm for object color, shape, and size detection},
  author={Abdullah-Al-Noman, Md and Eva, Anika Nawer and Yeahyea, Tabassum Binth and Khan, Riasat},
  journal={Journal of Robotics and Control (JRC)},
  volume={3},
  number={2},
  pages={180--186},
  year={2022}
}


@manual{DatenblattGreifer,
  author    = {Robotiq Inc.},
  title     = {3-Finger Adaptive Robot Gripper Instruction Manual},
  year      = {2019},
  note      = {Version 20190221},
  url       = {https://robotiq.com/support},
  organization = {Robotiq Inc.},
}

@misc{robotiq2025Website,
  author       = {{Robotiq}},
  title        = {Adaptive Greifer | Robotiq},
  year         = {2025},
  howpublished = {\url{https://robotiq.com/de/produkte/adaptiven-greifer#Three-Finger-Gripper}},
  note         = {Zugriff am: 28. Februar 2025}
}


@misc{HighLevel,
  author       = {{Coursera}},
  title        = {Low-Level vs. High-Level Programming Languages},
  year         = {2024},
  howpublished = {\url{https://www.coursera.org/articles/high-level-programming-languages}},
  note         = {Zugriff am: 1. März 2025}
}



@incollection{BuchKamera,
  author    = {Hermann Winner and Stephan Hakuli and Felix Lotz and Christina Singer},
  title     = {Maschinelles Sehen},
  booktitle = {Handbuch Fahrerassistenzsysteme},
  editor    = {Hermann Winner and Stephan Hakuli and Felix Lotz and Christina Singer},
  edition   = {3},
  publisher = {Springer Vieweg},
  year      = {2021},
  chapter   = {21},
  address   = {Wiesbaden}
}

@article{PaperTendenzKamera,
  title={Computer vision-based robotic arm for object color, shape, and size detection},
  author={Abdullah-Al-Noman, Md and Eva, Anika Nawer and Yeahyea, Tabassum Binth and Khan, Riasat},
  journal={Journal of Robotics and Control (JRC)},
  volume={3},
  number={2},
  pages={180--186},
  year={2022}
}

@article{KameraSensorenBEschriftung,
author = {Leone, Alessandro and Rescio, Gabriele and Diraco, Giovanni and Manni, Andrea and Siciliano, P. and Caroppo, Andrea},
year = {2022},
month = {06},
pages = {4893},
title = {Ambient and Wearable Sensor Technologies for Energy Expenditure Quantification of Ageing Adults},
volume = {22},
journal = {Sensors},
doi = {10.3390/s22134893}
}


@manual{IntelRealSenseD400,
  author    = {{Intel Corporation}},
  title     = {Intel® RealSense™ Product Family D400 Series Datasheet},
  year      = {2023},
  url       = {https://www.intelrealsense.com},
}

@misc{IntelRealSenseSDK,
  author    = {Intel Corporation},
  title     = {Intel RealSense SDK 2.0},
  year      = {2025},
  url       = {https://github.com/IntelRealSense/librealsense},
  note      = {Zugriff am 3. März 2025}
}


@unknown{20years,
author = {Zou, Zhengxia and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
year = {2019},
month = {05},
pages = {},
title = {Object Detection in 20 Years: A Survey},
doi = {10.48550/arXiv.1905.05055}
}



@inproceedings{Python,
  author    = {Basavaraj M U and H Raghuram and Mohana},
  title     = {Real Time Object Distance and Dimension Measurement using Deep Learning and OpenCV},
  booktitle = {Proceedings of the Third International Conference on Artificial Intelligence and Smart Energy (ICAIS 2023)},
  year      = {2023},
  publisher = {IEEE},
  doi       = {10.1109/ICAIS56108.2023.10073888}
}

@misc{waver,
  author = {Waverley Software},
  title = {Python for AI and ML},
  year = {2024},
  url = {https://waverleysoftware.com/blog/python-for-ai-and-ml/},
  note = {Letzter Zugriff: 11. März 2025}
}

@misc{upwork2024,
  author = {Upwork},
  title = {Best AI Programming Language},
  year = {2024},
  url = {https://www.upwork.com/resources/best-ai-programming-language},
  note = {Letzter Zugriff: 11. März 2025}
}

@inproceedings{YOLO1,
  author    = {Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi},
  title     = {You Only Look Once: Unified, Real-Time Object Detection},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2016},
  pages     = {779--788},
  doi       = {10.1109/CVPR.2016.91},
  url       = {http://pjreddie.com/yolo/}
}


@article{Yolov8_reason,
author = {Hussain, Muhammad},
year = {2023},
month = {06},
pages = {677},
title = {YOLO-v1 to YOLO-v8, the Rise of YOLO and Its Complementary Nature toward Digital Manufacturing and Industrial Defect Detection},
volume = {11},
journal = {Machines and Tooling},
doi = {10.3390/machines11070677}
}


@misc{IBM_CNN,
  author       = {{IBM Research}},
  title        = {Was sind Convolutional Neural Networks?},
  year         = {2024},
  howpublished = {\url{https://www.ibm.com/de-de/think/topics/convolutional-neural-networks}},
  note         = {Zugriff am 18. März 2025}
}

@book{Make,
  author    = {Tariq Rashid},
  title     = {Make Your Own Neural Network},
  year      = {2016},
  publisher = {CreateSpace Independent Publishing Platform},
  pages     = {4--5},
  isbn      = {978-1530826605}
}

@ARTICLE{LeCun2,
  author={LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  journal={Neural Computation}, 
  title={Backpropagation Applied to Handwritten Zip Code Recognition}, 
  year={1989},
  volume={1},
  number={4},
  pages={541-551},
  keywords={},
  doi={10.1162/neco.1989.1.4.541}}

@article{FUKUSHIMA1982455,
title = {Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position},
journal = {Pattern Recognition},
volume = {15},
number = {6},
pages = {455-469},
year = {1982},
issn = {0031-3203},
doi = {https://doi.org/10.1016/0031-3203(82)90024-3},
url = {https://www.sciencedirect.com/science/article/pii/0031320382900243},
author = {Kunihiko Fukushima and Sei Miyake},
keywords = {Visual pattern recognition, Deformation-resistant, Unsupervised learning, Self-organization, Neural network model, Visual nervous system},
abstract = {Suggested by the structure of the visual nervous system, a new algorithm is proposed for pattern recognition. This algorithm can be realized with a multilayered network consisting of neuron-like cells. The network, “neocognitron”, is self-organized by unsupervised learning, and acquires the ability to recognize stimulus patterns according to the differences in their shapes: Any patterns which we human beings judge to be alike are also judged to be of the same category by the neocognitron. The neocognitron recognizes stimulus patterns correctly without being affected by shifts in position or even by considerable distortions in shape of the stimulus patterns.}
}


@misc{MediumBackpropagation,
  author    = {Biased Algorithms},
  title     = {Backpropagation vs. Gradient Descent},
  year      = {2024},
  url       = {https://medium.com/biased-algorithms/backpropagation-vs-gradient-descent-19e3f55878a6},
  note      = {Zugriff am 18. März 2025}
}

@misc{ultralytics_nms,
  author    = {Ultralytics},
  title     = {Non-Maximum Suppression (NMS) - Ultralytics Glossary},
  year      = {2024},
  url       = {https://www.ultralytics.com/de/glossary/non-maximum-suppression-nms},
  note      = {Zugriff am 18. März 2025}
}



@misc{YOLO11UltralyticsBenchmarking,
  author    = {Ultralytics},
  title     = {YOLO11 Models - Ultralytics Documentation},
  year      = {2024},
  url       = {https://docs.ultralytics.com/de/models/yolo11/},
  note      = {Zugriff am 19. März 2025}
}

@unknown{ArchitectureYOLO8-11,
author = {Hidayatullah, Priyanto and Syakrani, N. and Sholahuddin, Muhammad and Gelar, Trisna and Tubagus, Refdinal},
year = {2025},
month = {01},
pages = {},
title = {YOLOv8 to YOLO11: A Comprehensive Architecture In-depth Comparative Review},
doi = {10.48550/arXiv.2501.13400}
}

@unknown{Enhancements,
author = {Khanam, Rahima and Hussain, Muhammad},
year = {2024},
month = {10},
pages = {},
title = {YOLOv11: An Overview of the Key Architectural Enhancements},
doi = {10.48550/arXiv.2410.17725}
}



@article{MediumYolo11,
  author    = {S. Nikhileswara Rao},
  title     = {{YOLOv11 Explained: Next-Level Object Detection with Enhanced Speed and Accuracy}},
  journal   = {Medium},
  year      = {2024},
  url       = {https://medium.com/@nikhil-rao-20/yolov11-explained-next-level-object-detection-with-enhanced-speed-and-accuracy-2dbe2d376f71}
}

@article{nearest-neighbor,
  author    = {Abhishek Kumar Pandey},
  title     = {{Nearest Neighbor Interpolation}},
  journal   = {Medium},
  year      = {2023},
  url       = {https://medium.com/@akp83540/nearest-neighbor-interpolation-84c956ee56a3}
}

@article{coobots,
author = {Perez, Luis and Rodríguez, Íñigo and Rodríguez, Nuria and Usamentiaga, Rubén and García, Daniel},
year = {2016},
month = {03},
pages = {335},
title = {Robot Guidance Using Machine Vision Techniques in Industrial Environments: A Comparative Review},
volume = {16},
journal = {Sensors},
doi = {10.3390/s16030335}
}


@INPROCEEDINGS{oneShot,
  author={Huang, Bingyao and Tang, Ying},
  booktitle={2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Fast 3D reconstruction using one-shot spatial structured light}, 
  year={2014},
  volume={},
  number={},
  pages={531-536},
  keywords={Image color analysis;Color;Three-dimensional displays;Hamming distance;Cameras;Real-time systems;Image reconstruction;structured light;3D reconstruction;color-encoded;one-shot;spatial multiplexed;hamming distance},
  doi={10.1109/SMC.2014.6973962}}


@misc{kim_pixel_to_point_2020,
  author       = {Kim, Neworld},
  title        = {How Could You Make Pixel to Point Conversion?},
  year         = {2020},
  url          = {https://medium.com/newworld-kim/how-could-you-make-pixel-to-point-conversion-ed3672263f88},
  note         = {Accessed: 2025-03-25},
  howpublished = {\url{https://medium.com/newworld-kim/how-could-you-make-pixel-to-point-conversion-ed3672263f88}}
}

@misc{Projekticn_learnopencv_geometry_formation,
  author       = {Satya Mallick},
  title        = {Geometry of Image Formation},
  year         = {2018},
  url          = {https://learnopencv.com/geometry-of-image-formation/},
  note         = {Accessed: 2025-03-25},
  howpublished = {\url{https://learnopencv.com/geometry-of-image-formation/}}
}



@misc{VisualPresets,
  author       = {{Intel Corporation}},
  title        = {D400 Series Visual Presets Documentation},
  year         = {2025},
  howpublished = {\url{https://dev.intelrealsense.com/docs/d400-series-visual-presets}},
  note         = {Zugriff am: 25. März 2025}
}


@misc{yaml,
  author       = {Ultralytics},
  title        = {YOLOv11 Model Configuration File},
  year         = {2024},
  howpublished = {\url{https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/11/yolo11.yaml}},
  note         = {Accessed: 2025-03-26},
  url          = {https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/11/yolo11.yaml}
}

@online{pandas2024,
  author       = {{The pandas development team}},
  title        = {pandas: powerful Python data analysis toolkit},
  year         = {2024},
howpublished =  {https://pandas.pydata.org/}},
  url          = {https://pandas.pydata.org/},
  note         = {Accessed: 2025-03-29}

}

@online{chip_fps_auge,
  author       = {{CHIP-Redaktion}},
  title        = {Wie viel FPS hat das Auge? Was Sie wahrnehmen können},
  year         = {2024},
  url          = {https://praxistipps.chip.de/wie-viel-fps-hat-das-auge-was-sie-wahrnehmen-koennen_183592},
  note         = {Zugriff am 29. März 2025},
  organization = {CHIP Praxistipps}
}

@software{yolo11_ultralytics_software,
  author = {Glenn Jocher and Jing Qiu},
  title = {Ultralytics YOLO11},
  version = {11.0.0},
  year = {2024},
  url = {https://github.com/ultralytics/ultralytics},
  orcid = {0000-0001-5950-6979, 0000-0002-7603-6750, 0000-0003-3783-7069},
  license = {AGPL-3.0}
}
@misc{ultralytics_repo,
  author       = {Ultralytics},
  title        = {Ultralytics: Open-Source Vision AI},
  year         = {2025},
  url          = {https://github.com/ultralytics/ultralytics},
  note         = {Zugriff am 29. März 2025},
  howpublished = {\url{https://github.com/ultralytics/ultralytics}}
}

@online{ultralytics_about,
  author       = {Ultralytics},
  title        = {Über Ultralytics – Mission, Geschichte und KI-Vision},
  year         = {2025},
  url          = {https://www.ultralytics.com/de/about},
  note         = {Zugriff am 29. März 2025},
  organization = {Ultralytics}
}


@misc{COCO_lin2015microsoft,
      title={Microsoft COCO: Common Objects in Context},
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@online{IntelRealSenseMeasure,
  author       = {{Intel Corporation}},
  title        = {Measuring Depth Accuracy and Consistency},
  year         = 2020,
  url          = {https://dev.intelrealsense.com/docs/rs-measure},
  urldate      = {2025-03-29},
  note         = {Zugriff am 29.03.2025},
}

@online{pyrealsense2docs,
  author       = {{Intel RealSense SDK}},
  title        = {pyrealsense2 --- Python-API-Dokumentation},
  year         = 2024,
  url          = {https://intelrealsense.github.io/librealsense/python_docs/_generated/pyrealsense2.html#module-pyrealsense2},
  urldate      = {2025-03-29},
  note         = {Zugriff am 29.03.2025},
}


@misc{datacamp_activation_functions,
  author       = {DataCamp},
  title        = {Einführung in Aktivierungsfunktionen in neuronalen Netzen},
  year         = {2024},
  url          = {https://www.datacamp.com/de/tutorial/introduction-to-activation-functions-in-neural-networks},
  note         = {Zugriff am: 31. März 2025}
}

@misc{openCV,
  author       = {Oliver Moser},
  title        = {Einführung in Computer Vision mit OpenCV und Python},
  year         = {2017},
  url          = {https://www.codecentric.de/wissens-hub/blog/einfuehrung-in-computer-vision-mit-opencv-und-python},
  note         = {Zugriff am: 31. März 2025}
}
@misc{wut_modbus_register,
  author    = {{Wiesemann \& Theis GmbH}},
  title     = {Modbus – Registerarten},
  howpublished = {\url{https://www.wut.de/e-57www-04-apde-000.php}},
  note      = {Zugriff am 2. April 2025}
}

@misc{pandas2024,
  author       = {{pandas development team}},
  title        = {Pandas: Python Data Analysis Library},
  year         = {2024},
  url          = {https://pandas.pydata.org/},
  note         = {Accessed: 2025-04-05}
}
@misc{reddy2024rtdetr,
  author       = {Nandini Lokesh Reddy},
  title        = {RT-DETR: The Next Evolution in Real-Time Object Detection},
  year         = {2024},
  url          = {https://medium.com/@nandinilreddy/rt-detr-the-next-evolution-in-real-time-object-detection-aa1c7880f368},
  note         = {Online; accessed 5-April-2025}
}


@misc{ultralytics_rtdetr,
  author       = {Ultralytics},
  title        = {RT-DETR (Echtzeit-Detektions-Transformator)},
  year         = {2024},
  url          = {https://docs.ultralytics.com/de/models/rtdetr/#overview},
  note         = {Online; Zugriff am 5. April 2025}
}


@online{EVS_Sensoren,
  author = {{EVS Robotics}},
  title = {Arten von Sensoren in der Robotik},
  year = {2024},
  url = {https://www.evsint.com/de/types-of-sensors-in-robotics/},
  note = {Zugriff am 06.04.2025}
}
@misc{intel_rs_measure,
  author = {{Intel Corporation}},
  title = {RealSense Depth Measurement Documentation},
  year = {2023},
  url = {https://dev.intelrealsense.com/docs/rs-measure},
  note = {Zugriff am 06.04.2025}
}

@misc{robotiq3f_py,
  author       = {Bahaa Rehman},
  title        = {robotiq3f\_py – Python Library for Robotiq 3-Finger Gripper},
  year         = {2022},
  url          = {https://github.com/baha2r/robotiq3f_py},
  howpublished = {\url{https://github.com/baha2r/robotiq3f_py}},
  note         = {Zugriff am: 6. April 2025}
}


@misc{mediapipe_hand_landmarker,
  author       = {{Google AI}},
  title        = {MediaPipe Hand Landmarker},
  year         = {2024},
  howpublished = {\url{https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker?hl=de}},
  note         = {Zugriff am 06.04.2025}
}
@misc{ultralytics_transfer_learning,
  author       = {{Ultralytics}},
  title        = {Transfer Learning – Ultralytics Glossar},
  year         = {2024},
  howpublished = {\url{https://www.ultralytics.com/de/glossary/transfer-learning}},
  note         = {Zugriff am 06.04.2025}
}
@misc{ultralytics_onnx_integration,
  author       = {{Ultralytics}},
  title        = {ONNX Integration – Ultralytics Documentation},
  year         = {2024},
  howpublished = {\url{https://docs.ultralytics.com/de/integrations/onnx/#key-features-of-onnx-models}},
  note         = {Zugriff am 06.04.2025}
}
@online{navarai2023,
  author    = {Navarai},
  title     = {Understanding and Mitigating Catastrophic Forgetting in Machine Learning},
  year      = {2023},
  url       = {https://medium.com/@navarai/understanding-and-mitigating-catastrophic-forgetting-in-machine-learning-d5caa93d375e},
  note      = {Medium, accessed April 7, 2025}
}
